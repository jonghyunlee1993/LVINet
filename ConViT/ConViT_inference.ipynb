{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59855f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fpath</th>\n",
       "      <th>Y</th>\n",
       "      <th>fname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/pos_A00032_39919-4762.png</td>\n",
       "      <td>1</td>\n",
       "      <td>pos_A00032_39919-4762.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/neg_A00020_30254-10225.png</td>\n",
       "      <td>0</td>\n",
       "      <td>neg_A00020_30254-10225.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/pos_A00007_36844-16740.png</td>\n",
       "      <td>1</td>\n",
       "      <td>pos_A00007_36844-16740.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/neg_A00041_32121-6353.png</td>\n",
       "      <td>0</td>\n",
       "      <td>neg_A00041_32121-6353.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/neg_A00011_26462-14125.png</td>\n",
       "      <td>0</td>\n",
       "      <td>neg_A00011_26462-14125.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>../data/pos_A00036_24924-29724.png</td>\n",
       "      <td>1</td>\n",
       "      <td>pos_A00036_24924-29724.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>../data/pos_A00042_24414-32208.png</td>\n",
       "      <td>1</td>\n",
       "      <td>pos_A00042_24414-32208.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>../data/pos_A00008_8902-13743.png</td>\n",
       "      <td>1</td>\n",
       "      <td>pos_A00008_8902-13743.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>../data/pos_A00008_40683-11016.png</td>\n",
       "      <td>1</td>\n",
       "      <td>pos_A00008_40683-11016.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>../data/pos_A00030_9474-29311.png</td>\n",
       "      <td>1</td>\n",
       "      <td>pos_A00030_9474-29311.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>973 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  fpath  Y                       fname\n",
       "0     ../data/pos_A00032_39919-4762.png  1   pos_A00032_39919-4762.png\n",
       "1    ../data/neg_A00020_30254-10225.png  0  neg_A00020_30254-10225.png\n",
       "2    ../data/pos_A00007_36844-16740.png  1  pos_A00007_36844-16740.png\n",
       "3     ../data/neg_A00041_32121-6353.png  0   neg_A00041_32121-6353.png\n",
       "4    ../data/neg_A00011_26462-14125.png  0  neg_A00011_26462-14125.png\n",
       "..                                  ... ..                         ...\n",
       "968  ../data/pos_A00036_24924-29724.png  1  pos_A00036_24924-29724.png\n",
       "969  ../data/pos_A00042_24414-32208.png  1  pos_A00042_24414-32208.png\n",
       "970   ../data/pos_A00008_8902-13743.png  1   pos_A00008_8902-13743.png\n",
       "971  ../data/pos_A00008_40683-11016.png  1  pos_A00008_40683-11016.png\n",
       "972   ../data/pos_A00030_9474-29311.png  1   pos_A00030_9474-29311.png\n",
       "\n",
       "[973 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROJECT_NAME = \"vit\"\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import timm\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler, RandomSampler\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "import torchmetrics\n",
    "from torchmetrics.functional import confusion_matrix\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "test_df = glob.glob(\"../data/*.png\")\n",
    "test_df = pd.DataFrame(test_df, columns=[\"fpath\"])\n",
    "test_df.loc[:, \"Y\"] = test_df.fpath.map(lambda x: 1 if x.split(\"/\")[-1].split(\"_\")[0] == \"pos\" else 0)\n",
    "test_df.loc[:, \"fname\"] = test_df.fpath.map(lambda x: x.split(\"/\")[-1])\n",
    "\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51e53f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_transforms = A.Compose([ \n",
    "    A.Resize(width=224, height=224, p=1.0),\n",
    "    A.Normalize(p=1.0),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "\n",
    "class LVIDataset(Dataset):\n",
    "    def __init__(self, df, transforms):\n",
    "        self.df = df\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.df.loc[idx, \"fname\"]\n",
    "        target = self.df.loc[idx, \"Y\"]\n",
    "        fpath = self.df.loc[idx, \"fpath\"]\n",
    "        image  = cv2.imread(fpath)\n",
    "    \n",
    "        augmented = self.transforms(image=image)\n",
    "        image = augmented['image']  \n",
    "        \n",
    "        return image, torch.tensor(target).long(), fname\n",
    "    \n",
    "    \n",
    "test_dataset = LVIDataset(test_df, valid_transforms)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, \n",
    "                              num_workers=16, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dde2f524",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda3/envs/pathology/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=[1])` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=[1])` instead.\n",
      "  rank_zero_deprecation(\n",
      "Using 16bit None Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "class LVIPatchClassifier(pl.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        \n",
    "    \n",
    "    def step(self, batch):\n",
    "        X, y, fname = batch\n",
    "        pred = self.model(X).squeeze(-1)\n",
    "        loss = F.cross_entropy(pred, y.long())\n",
    "        \n",
    "        pred = F.softmax(pred)[:, 1]\n",
    "        \n",
    "        recall_ = torchmetrics.functional.recall(pred, y.long(), task=\"binary\")\n",
    "        auroc_ = torchmetrics.functional.auroc(pred, y.long(), task=\"binary\")\n",
    "        auprc_ = torchmetrics.functional.average_precision(pred, y.long(), task=\"binary\")\n",
    "        \n",
    "        return pred, y, fname, loss\n",
    "    \n",
    "    \n",
    "    def logging(self, logging_object, mode=\"train\"):\n",
    "        auroc, auprc = logging_object\n",
    "        \n",
    "        self.log(f'{mode}_auroc', auroc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(f'{mode}_auprc', auprc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        _, _, _, loss = self.step(batch)\n",
    "        self.log(\"train_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        preds, y, _, loss = self.step(batch)\n",
    "        self.log(\"valid_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        preds, y, _, loss = self.step(batch)\n",
    "        self.log(\"test_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "   \n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        preds, y, fname, loss = self.step(batch)\n",
    "\n",
    "        return {\"preds\": preds, \"target\": y, \"fname\": fname}\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=LEARNING_RATE)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10 * len(train_dataloader))\n",
    "        \n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}\n",
    "    \n",
    "model = timm.create_model(\"convit_small\", pretrained=True, num_classes=2)\n",
    "classifier = LVIPatchClassifier(model)\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(monitor='valid_auroc', mode=\"max\",\n",
    "                    save_top_k=1, dirpath=f'weights/{PROJECT_NAME}', filename='{epoch:03d}-{valid_loss:.4f}-{valid_recall:.4f}-{valid_auroc:.4f}-{valid_auprc:.4f}'),\n",
    "]\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=100, gpus=[1], \n",
    "                     enable_progress_bar=True, \n",
    "                     callbacks=callbacks, precision=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f999d12e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "959c5908d9ca49e083c1b95d7b64ece5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688134/636630907.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred = F.softmax(pred)[:, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 0.9184\n",
      "AUPRC: 0.8726\n",
      "Accuracy: 0.8674\n",
      "Precision: 0.7781\n",
      "Recall: 0.8013\n",
      "F1 score: 0.7896\n",
      "Confusion matrix\n",
      "[[602  69]\n",
      " [ 60 242]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score, recall_score, confusion_matrix, accuracy_score, precision_score, f1_score\n",
    "\n",
    "classifier = LVIPatchClassifier(model).load_from_checkpoint(\n",
    "    \"weights/convit_lightning.ckpt\", model=model, strict=False)\n",
    "\n",
    "pred = trainer.predict(classifier, test_dataloader)\n",
    "\n",
    "fname_list = []\n",
    "pred_list = []\n",
    "target_list = []\n",
    "for batch in pred:\n",
    "    fname_list += batch['fname']\n",
    "    pred_list += batch['preds'].detach().cpu().numpy().tolist()\n",
    "    target_list += batch['target'].detach().cpu().numpy().tolist()\n",
    "    \n",
    "print(f\"AUROC: {roc_auc_score(target_list, pred_list).round(4)}\")\n",
    "print(f\"AUPRC: {average_precision_score(target_list, pred_list).round(4)}\")\n",
    "print(f\"Accuracy: {accuracy_score(target_list, [1 if pred >= 0.5 else 0 for pred in pred_list]).round(4)}\")\n",
    "print(f\"Precision: {precision_score(target_list, [1 if pred >= 0.5 else 0 for pred in pred_list]).round(4)}\")\n",
    "print(f\"Recall: {recall_score(target_list, [1 if pred >= 0.5 else 0 for pred in pred_list]).round(4)}\")\n",
    "print(f\"F1 score: {f1_score(target_list, [1 if pred >= 0.5 else 0 for pred in pred_list]).round(4)}\")\n",
    "\n",
    "print(\"Confusion matrix\")\n",
    "print(confusion_matrix(target_list, [1 if pred >= 0.5 else 0 for pred in pred_list]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0cbe441",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({\n",
    "    \"fname\": fname_list,\n",
    "    \"target\": target_list,\n",
    "    \"pred\": pred_list\n",
    "})\n",
    "\n",
    "pred_df.to_csv(\"output/convit_inference.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517a59d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
